========================================
DTAMで復元する3Dアニメの世界
========================================

:執筆: @woodrush924


概要
================

アニメの世界の中を散歩したい！
誰もが夢見るであろうその願望は，
アニメの為の3DCG技術，そしてロボットの為の3次元再構成技術が出逢うとき，
急速に現実へ近くなる．
この章では，街などを撮影した動画像から街の3Dモデルを得るためのDTAMという手法を，
リアルな3DCGが用いられているアニメの映像に適用することにより，
放送されているアニメの映像のみからその中の世界を再構成しようとするものである．

DTAMによる3次元再構成
================

カメラを搭載した自律型の探索ロボットに，カメラの映像のみから探索地域の3Dモデルを作らせることを考える．
GPSが一切無い，遠くの惑星のような地域で探索を行うには，
周囲の3Dモデル（地図に対応）を作るタスクと，3Dモデル中での自分の位置を同時に推定することが必要になる．
このような問題設定，およびそれを解く方法を総称してSLAM (Simultaneous Localization and Mapping) と呼ぶ．
DTAM (Dense Tracking and Mapping [dtam]_) とは，SLAMの一種で，単眼RGB画像の全画素を入力としてSLAMを行う方法である．
DTAMが行っている事を人間で喩えるなら，片目だけ開けた状態で部屋の中を動きまわり，その部屋の間取り図を描きながら間取り図中の自分の位置を推定するということだ．
この作業は「片目」という条件のせいで，コンピュータにとっては難しい．
例えばKinect Fusion [kinect]_では，
画像情報の他にKinectに搭載されている距離センサの情報を組み合わせた，RGB-D画像を用いて3次元再構成を行っている．
距離センサが不要な方法として，人間の目と同様の原理で2台の離れたカメラを用いて3次元再構成を行う方法もあるが，
こちらは2台目のカメラが必要となる．
DTAMは，そんな3次元再構成を一台の単眼RGBカメラの映像のみで実行している． 

また，DTAMの最大の特徴は，画像中の全画素の情報を用いて推定を行っていることにある．
従来のSLAMでは，画像中の限られた点（特徴点）のみを用いて自己位置推定と3次元再構成を行っていた．
これに対し，DTAMでは画像中の全画素を用いているため，従来法に比べて非常に正確かつリッチなモデルを得ることができる．


定式化
===================

(執筆中)

Regularized Energy Functional の構成

Regularized Energy Functional の最適化

方法
===================

以下の動画を使用した．

* ラブライブ！1期OP ステージ映像 (XX:XX - XX:XX)
* ごちうさ2期OP 冒頭部分 (XX:XX - XX:XX)

DTAMの実装には，(TODO)のOpenDTAM[opendtam]_を利用した．
これは，画像の時系列をpng画像の列として与え，DTAMにより点群を出力するコードである．

使用環境：Ubuntu 15.04, GeForce GTX 960, Intel Core i7 XXXX, etc etc...

結果
================
（画像x2）

結論
================
今回は時間がなかったため行わなかったが，得られたモデルを使ってOculus Riftで歩き回ると迫力あるかもしれない．
また，点群をメッシュに変換したり，テクスチャを得たりすることで，
MMDモデルにしても捗ると思われる．



参考文献
================

* .. [dtam] Richard A. Newcombe, Steven J. Lovegrove and Andrew J. Davison, DTAM: Dense Tracking and Mapping in Real-Time, (TODO)
* .. [kinect] Kinect Fusion
* .. [opendtam] OpenDTAM. https://github.com/anuranbaka/OpenDTAM
